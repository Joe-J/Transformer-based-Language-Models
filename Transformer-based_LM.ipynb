{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yl2Psdw2BNRd"
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzZupRr6BNRf"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VZGcQpUPqDw6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljiang/anaconda3/envs/u2pl/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, MultiheadAttention\n",
    "from torch import einsum\n",
    "\n",
    "def max_neg_value(tensor):\n",
    "    return -torch.finfo(tensor.dtype).max\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def linear_attn(q, k, v, kv_mask=None):\n",
    "    dim = q.shape[-1]\n",
    "    if exists(kv_mask):\n",
    "        mask_value = max_neg_value(q)\n",
    "        mask = kv_mask[:, None, :, None]\n",
    "        k = k.masked_fill_(~mask, mask_value)\n",
    "        v = v.masked_fill_(~mask, 0.)\n",
    "        del mask\n",
    "    q = q.softmax(dim=-1)\n",
    "    k = k.softmax(dim=-2)\n",
    "    q = q * dim ** -0.5\n",
    "\n",
    "    context = einsum('bhnd,bhne->bhde', k, v)\n",
    "    attn = einsum('bhnd,bhde->bhne', q, context)\n",
    "    return attn.reshape(*q.shape)\n",
    "\n",
    "class LinearAttentionLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super(LinearAttentionLayer, self).__init__()\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.nhead = nhead\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, kv_mask=None):\n",
    "        q = self.q_linear(query)\n",
    "        k = self.k_linear(key)\n",
    "        v = self.v_linear(value)\n",
    "\n",
    "        q = q.view(query.size(0), -1, self.nhead, query.size(-1)//self.nhead).transpose(1, 2)\n",
    "        k = k.view(key.size(0), -1, self.nhead, key.size(-1)//self.nhead).transpose(1, 2)\n",
    "        v = v.view(value.size(0), -1, self.nhead, value.size(-1)//self.nhead).transpose(1, 2)\n",
    "\n",
    "        attn_weights = linear_attn(q, k, v, kv_mask=kv_mask)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(query.size(0), -1, query.size(-1))\n",
    "\n",
    "        return output\n",
    "class LinearAttentionMultiheadAttention(MultiheadAttention):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None):\n",
    "        super(LinearAttentionMultiheadAttention, self).__init__(embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim)\n",
    "\n",
    "        # 替换 self-attention 层\n",
    "        self.attention = LinearAttentionLayer(embed_dim, num_heads, dropout=dropout)\n",
    "\n",
    "class LinearAttentionTransformerEncoderLayer(TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(LinearAttentionTransformerEncoderLayer, self).__init__(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "\n",
    "        # 替换 self_attn 层\n",
    "        self.self_attn = LinearAttentionMultiheadAttention(d_model, nhead, dropout=dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "fjydQurRBNRf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, linear_attention: bool = False,dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        if linear_attention:\n",
    "            encoder_layers = LinearAttentionTransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        else:\n",
    "            encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            \"\"\"\n",
    "            src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YVEAuUV9BNRg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSyToB7hBNRg"
   },
   "source": [
    "## Load and batch data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CULPbJBBNRg"
   },
   "source": [
    "This tutorial uses ``torchtext`` to generate Wikitext-2 dataset.\n",
    "To access torchtext datasets, please install torchdata following instructions at https://github.com/pytorch/data.\n",
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "bfd46bac58a44215bd33d57c8231d627",
      "2e62b29c76ed484baa01a84d51f7a8f5",
      "317647bc55b44fa7a37eb49a27034aa0",
      "24269a54be3e45f69a03a951b58c7ea9",
      "00a9572004184110a072cd8efd0ed8b2",
      "1ae53b9c451c4e85a788263841a9673d",
      "0035edbde4bd4c5f88204d663840d82b",
      "0481b1b1cd154fcc88aec905c51af76f",
      "d5d0f4e93d13457a928f9a6fe0354d62",
      "ac4d9ef301f5458388e7651a9fa97ff4",
      "f73822f80c9c422b8ab94736e307f7c7",
      "4fe123833cff481cad9f6b0437193724",
      "378a9ee69cf042979ecb8ca32e49839b",
      "f95a2b58d6ca464db7a90dd4381c84ff",
      "23d471228b4547edb3011815129cf0f4",
      "687d1b24ef684204b43e56a0d8106376",
      "9d229b4e30cd413b97cd73f868188fae",
      "fb62786e1bc84ea3abee6a2e48ae1c73",
      "793c30e1bde44c13afe449303a34daac",
      "5a4e7b4c62ef4df79fefcbace8e9c26f",
      "16eebdab9884480195c4db35bea2d0c7",
      "c1ad28bc7d82404289f447648c9b4246",
      "84215a9176d143c09622554635a9d39b",
      "77a3a9ea86c24c3d840c8abfab3ec528",
      "2ab8c56071a14a09b1e497c76c5e01e0",
      "8a8472829d9c4a599365f08b658cb851",
      "39808e3db3984ee2a0da0b7b89fcc886",
      "c59107dcb845431ab068406dcfb92391",
      "f09319c0fe5c466c9663e591a3d7d650",
      "8b03415a476c48f6ad8dea78f21385b8",
      "1e3949a6d8154009a659945c790e12ef",
      "5de89c686c3c42d4b741790ff5b828e2",
      "6276a7d486aa41309f8e0e05948d1eed",
      "22f75c9e1af44d329d6374c0b6dd3a72",
      "a54297f9f4f84544afa38a033c8c4025",
      "386d2fea56fa469aba4aaad455d84476",
      "295b5b9f453c4cd48d2b5c96911ae3c8",
      "884e7212ec214bd8aa82939a280e22b5",
      "f07305b494ec4989afdff7e2a182d01e",
      "98fd8faddb2842379c5f684262e4bdfc",
      "a811e921997e4b5ea50bb54f11c0e2d2",
      "724a33f4afc5488ab7e967f87991d2e5",
      "b6d411d16d4e4aefa1b0bb68c7ec92a2",
      "c8ef0767e75546bb9c0d743fe319203e"
     ]
    },
    "id": "QNzAg88IBNRh",
    "outputId": "22206c30-a078-4b06-cb2e-527caa7a81ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from torchtext.datasets import PennTreebank\n",
    "import pickle\n",
    "\n",
    "def save_dataset(dataset, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    return dataset\n",
    "\n",
    "# # 载入预训练的 GPT-2 分词器\n",
    "# model_name = \"gpt2\"\n",
    "# tokenizer_bpe = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# train_iter, val_iter, test_iter = PennTreebank()\n",
    "\n",
    "# def text_generator(raw_text_iter):\n",
    "#     for item in raw_text_iter:\n",
    "#         yield tokenizer_bpe.tokenize(item)\n",
    "# vocab = build_vocab_from_iterator(text_generator(train_iter), specials=['<unk>'])\n",
    "# vocab.set_default_index(vocab['<unk>'])\n",
    "# print(len(vocab))\n",
    "\n",
    "# 载入word tokenizer\n",
    "train_iter = PennTreebank(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    # data = [torch.tensor(vocab(tokenizer_bpe.tokenize(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = PennTreebank()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_dataset(train_data, \"./dataset/WikiText2/train_dataset.pkl\")\n",
    "# save_dataset(test_data, \"./dataset/WikiText2/test_dataset.pkl\")\n",
    "# save_dataset(val_data, \"./dataset/WikiText2/val_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wM05SlewCQbm",
    "outputId": "701fedda-795d-41c2-cc32-3401913df6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46220, 20])\n",
      "9922\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKbTVMTkBNRh"
   },
   "source": [
    "### Functions to generate input and target sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBxDuCLwBNRh"
   },
   "source": [
    "``get_batch()`` generates a pair of input-target sequences for\n",
    "the transformer model. It subdivides the source data into chunks of\n",
    "length ``bptt``. For the language modeling task, the model needs the\n",
    "following words as ``Target``. For example, with a ``bptt`` value of 2,\n",
    "we’d get the following two Variables for ``i`` = 0:\n",
    "\n",
    "<img src=\"file://../_static/img/transformer_input_target.png\">\n",
    "\n",
    "It should be noted that the chunks are along dimension 0, consistent\n",
    "with the ``S`` dimension in the Transformer model. The batch dimension\n",
    "``N`` is along dimension 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EqGg-qjYBNRh"
   },
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh9Kp3WJBNRh"
   },
   "source": [
    "## Initiate an instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tdY0jQcBNRh"
   },
   "source": [
    "The model hyperparameters are defined below. The ``vocab`` size is\n",
    "equal to the length of the vocab object.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_DhWVp8BNRh",
    "outputId": "c12514d5-d788-44eb-b19f-b4a80e72b482"
   },
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "linear_attention=True\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, linear_attention,dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M9Gb9bpBNRi"
   },
   "source": [
    "## Run the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhW7oFxRBNRi"
   },
   "source": [
    "We use [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)_\n",
    "with the [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)_\n",
    "(stochastic gradient descent) optimizer. The learning rate is initially set to\n",
    "5.0 and follows a [StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html)_\n",
    "schedule. During training, we use [nn.utils.clip_grad_norm\\_](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)_\n",
    "to prevent gradients from exploding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "POPz5t7DBNRi"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        output = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        loss = criterion(output_flat, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.8)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEmpyT07BNRi"
   },
   "source": [
    "Loop over epochs. Save the model if the validation loss is the best\n",
    "we've seen so far. Adjust the learning rate after each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "iOxFGqHBBNRi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self_attention transformer training\n",
      "| epoch   1 |   200/ 1320 batches | lr 5.00 | ms/batch  4.90 | loss  7.88 | ppl  2644.63\n",
      "| epoch   1 |   400/ 1320 batches | lr 5.00 | ms/batch  4.86 | loss  6.85 | ppl   948.60\n",
      "| epoch   1 |   600/ 1320 batches | lr 5.00 | ms/batch  4.84 | loss  6.28 | ppl   531.14\n",
      "| epoch   1 |   800/ 1320 batches | lr 5.00 | ms/batch  4.89 | loss  5.99 | ppl   400.63\n",
      "| epoch   1 |  1000/ 1320 batches | lr 5.00 | ms/batch  4.86 | loss  5.82 | ppl   337.99\n",
      "| epoch   1 |  1200/ 1320 batches | lr 5.00 | ms/batch  4.85 | loss  5.70 | ppl   298.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.70s | valid loss  5.66 | valid ppl   285.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 1320 batches | lr 4.75 | ms/batch  4.87 | loss  5.61 | ppl   272.83\n",
      "| epoch   2 |   400/ 1320 batches | lr 4.75 | ms/batch  5.19 | loss  5.57 | ppl   263.73\n",
      "| epoch   2 |   600/ 1320 batches | lr 4.75 | ms/batch  4.86 | loss  5.53 | ppl   252.20\n",
      "| epoch   2 |   800/ 1320 batches | lr 4.75 | ms/batch  4.89 | loss  5.46 | ppl   234.49\n",
      "| epoch   2 |  1000/ 1320 batches | lr 4.75 | ms/batch  4.86 | loss  5.43 | ppl   228.09\n",
      "| epoch   2 |  1200/ 1320 batches | lr 4.75 | ms/batch  4.85 | loss  5.43 | ppl   227.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.76s | valid loss  5.45 | valid ppl   233.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 1320 batches | lr 4.51 | ms/batch  4.92 | loss  5.39 | ppl   218.73\n",
      "| epoch   3 |   400/ 1320 batches | lr 4.51 | ms/batch  4.90 | loss  5.39 | ppl   218.48\n",
      "| epoch   3 |   600/ 1320 batches | lr 4.51 | ms/batch  4.93 | loss  5.37 | ppl   215.67\n",
      "| epoch   3 |   800/ 1320 batches | lr 4.51 | ms/batch  4.83 | loss  5.30 | ppl   200.64\n",
      "| epoch   3 |  1000/ 1320 batches | lr 4.51 | ms/batch  4.83 | loss  5.32 | ppl   204.05\n",
      "| epoch   3 |  1200/ 1320 batches | lr 4.51 | ms/batch  4.85 | loss  5.29 | ppl   198.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.71s | valid loss  5.39 | valid ppl   218.87\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "print(\"Self_attention transformer training\")\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    tempdir = \"./model/\"\n",
    "    name = \"SA\"\n",
    "    best_model_params_path = os.path.join(tempdir, str(name)+\"_best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_attention transformer training\n",
      "| epoch   1 |   200/ 1320 batches | lr 5.00 | ms/batch  5.34 | loss  7.97 | ppl  2895.92\n",
      "| epoch   1 |   400/ 1320 batches | lr 5.00 | ms/batch  4.94 | loss  6.84 | ppl   931.78\n",
      "| epoch   1 |   600/ 1320 batches | lr 5.00 | ms/batch  4.94 | loss  6.61 | ppl   740.60\n",
      "| epoch   1 |   800/ 1320 batches | lr 5.00 | ms/batch  4.96 | loss  6.50 | ppl   662.23\n",
      "| epoch   1 |  1000/ 1320 batches | lr 5.00 | ms/batch  4.91 | loss  6.24 | ppl   513.88\n",
      "| epoch   1 |  1200/ 1320 batches | lr 5.00 | ms/batch  4.93 | loss  6.00 | ppl   402.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.88s | valid loss  5.89 | valid ppl   360.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 1320 batches | lr 4.75 | ms/batch  4.98 | loss  5.83 | ppl   339.76\n",
      "| epoch   2 |   400/ 1320 batches | lr 4.75 | ms/batch  4.90 | loss  5.76 | ppl   317.95\n",
      "| epoch   2 |   600/ 1320 batches | lr 4.75 | ms/batch  4.89 | loss  5.77 | ppl   319.36\n",
      "| epoch   2 |   800/ 1320 batches | lr 4.75 | ms/batch  4.91 | loss  5.67 | ppl   291.30\n",
      "| epoch   2 |  1000/ 1320 batches | lr 4.75 | ms/batch  4.90 | loss  5.61 | ppl   273.87\n",
      "| epoch   2 |  1200/ 1320 batches | lr 4.75 | ms/batch  4.92 | loss  5.62 | ppl   276.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.77s | valid loss  5.55 | valid ppl   257.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 1320 batches | lr 4.51 | ms/batch  4.95 | loss  5.58 | ppl   266.06\n",
      "| epoch   3 |   400/ 1320 batches | lr 4.51 | ms/batch  4.90 | loss  5.54 | ppl   253.41\n",
      "| epoch   3 |   600/ 1320 batches | lr 4.51 | ms/batch  4.92 | loss  5.56 | ppl   260.78\n",
      "| epoch   3 |   800/ 1320 batches | lr 4.51 | ms/batch  4.93 | loss  5.47 | ppl   236.28\n",
      "| epoch   3 |  1000/ 1320 batches | lr 4.51 | ms/batch  4.92 | loss  5.47 | ppl   237.25\n",
      "| epoch   3 |  1200/ 1320 batches | lr 4.51 | ms/batch  4.92 | loss  5.47 | ppl   236.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.78s | valid loss  5.49 | valid ppl   242.42\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "print(\"Linear_attention transformer training\")\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    tempdir = \"./model/\"\n",
    "    name = \"LA\"\n",
    "    best_model_params_path = os.path.join(tempdir, str(name)+\"_best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWsuUhIhBNRi"
   },
   "source": [
    "## Evaluate the best model on the test dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKSgjYuN4QQb",
    "outputId": "9c0b22b3-6d4c-4325-81a8-e76419338800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| PTB|self attention|word| test loss  5.35 | test ppl   210.35\n",
      "=========================================================================================\n",
      "| PTB|linear attention|word| test loss  5.45 | test ppl   232.69\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "linear_attention = False\n",
    "model_self = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, linear_attention,dropout).to(device)\n",
    "model_self.load_state_dict(torch.load(\"./model/SA_best_model_params.pt\"))\n",
    "test_loss = evaluate(model_self, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| PTB|self attention|word| test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "\n",
    "linear_attention = True\n",
    "model_linear = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, linear_attention,dropout).to(device)\n",
    "model_linear.load_state_dict(torch.load(\"./model/LA_best_model_params.pt\"))\n",
    "test_loss_linear = evaluate(model_linear, test_data)\n",
    "test_ppl_linear = math.exp(test_loss_linear)\n",
    "\n",
    "\n",
    "print('=' * 89)\n",
    "print(f'| PTB|linear attention|word| test loss {test_loss_linear:5.2f} | '\n",
    "      f'test ppl {test_ppl_linear:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uazes85cDO7R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |PTB|self attention|BPE| test loss  9.56 | test ppl 14244.27\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training |PTB|self attention|BPE| test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)\n",
    "\n",
    "# test_loss_linear = evaluate(model_linear, test_data)\n",
    "# test_ppl_linear = math.exp(test_loss_linear)\n",
    "\n",
    "\n",
    "# print('=' * 89)\n",
    "# print(f'| End of training |PTB|linear attention|BPE| test loss {test_loss_linear:5.2f} | '\n",
    "#       f'test ppl {test_ppl_linear:8.2f}')\n",
    "# print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GG6cczjcBNRi",
    "outputId": "4924342e-80c7-47b6-afe8-7c31d5c52486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |WiKi-Text2|BPE| test loss  4.65 | test ppl   104.81\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# test_loss = evaluate(model, test_data)\n",
    "# test_ppl = math.exp(test_loss)\n",
    "# print('=' * 89)\n",
    "# print(f'| End of training |WiKi-Text2|BPE| test loss {test_loss:5.2f} | '\n",
    "#       f'test ppl {test_ppl:8.2f}')\n",
    "# print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnVpeXf4IcDF",
    "outputId": "0198e875-b2f5-4e09-feb0-86ad1851900e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |WiKi-Text2|Word| test loss  5.50 | test ppl   245.35\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# test_loss = evaluate(model, test_data)\n",
    "# test_ppl = math.exp(test_loss)\n",
    "# print('=' * 89)\n",
    "# print(f'| End of training |WiKi-Text2|Word| test loss {test_loss:5.2f} | '\n",
    "#       f'test ppl {test_ppl:8.2f}')\n",
    "# print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7ILpwXdTN_b",
    "outputId": "3cb3cb67-05d3-42e5-944d-7c89201b38ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |PTB|Word| test loss  5.23 | test ppl   187.41\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# test_loss = evaluate(model, test_data)\n",
    "# test_ppl = math.exp(test_loss)\n",
    "# print('=' * 89)\n",
    "# print(f'| End of training |PTB|Word| test loss {test_loss:5.2f} | '\n",
    "#       f'test ppl {test_ppl:8.2f}')\n",
    "# print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY0JmwowPofs",
    "outputId": "559dc8fc-ee86-4895-ac45-c4b81dbe0ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |PTB|BPE| test loss  4.53 | test ppl    93.14\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# test_loss = evaluate(model, test_data)\n",
    "# test_ppl = math.exp(test_loss)\n",
    "# print('=' * 89)\n",
    "# print(f'| End of training |PTB|BPE| test loss {test_loss:5.2f} | '\n",
    "#       f'test ppl {test_ppl:8.2f}')\n",
    "# print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z93SbtCOU7Bm",
    "outputId": "ab29b2c5-ddba-4e34-cf84-e8a5c6853e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training |PTB|linear attention|BPE| test loss  4.52 | test ppl    92.08\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training |PTB|linear attention|BPE| test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exE13BYrx-Qq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:u2pl]",
   "language": "python",
   "name": "conda-env-u2pl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0035edbde4bd4c5f88204d663840d82b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "00a9572004184110a072cd8efd0ed8b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0481b1b1cd154fcc88aec905c51af76f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16eebdab9884480195c4db35bea2d0c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ae53b9c451c4e85a788263841a9673d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e3949a6d8154009a659945c790e12ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "22f75c9e1af44d329d6374c0b6dd3a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a54297f9f4f84544afa38a033c8c4025",
       "IPY_MODEL_386d2fea56fa469aba4aaad455d84476",
       "IPY_MODEL_295b5b9f453c4cd48d2b5c96911ae3c8"
      ],
      "layout": "IPY_MODEL_884e7212ec214bd8aa82939a280e22b5"
     }
    },
    "23d471228b4547edb3011815129cf0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16eebdab9884480195c4db35bea2d0c7",
      "placeholder": "​",
      "style": "IPY_MODEL_c1ad28bc7d82404289f447648c9b4246",
      "value": " 456k/456k [00:00&lt;00:00, 10.4MB/s]"
     }
    },
    "24269a54be3e45f69a03a951b58c7ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac4d9ef301f5458388e7651a9fa97ff4",
      "placeholder": "​",
      "style": "IPY_MODEL_f73822f80c9c422b8ab94736e307f7c7",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 9.51MB/s]"
     }
    },
    "295b5b9f453c4cd48d2b5c96911ae3c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d411d16d4e4aefa1b0bb68c7ec92a2",
      "placeholder": "​",
      "style": "IPY_MODEL_c8ef0767e75546bb9c0d743fe319203e",
      "value": " 665/665 [00:00&lt;00:00, 24.5kB/s]"
     }
    },
    "2ab8c56071a14a09b1e497c76c5e01e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b03415a476c48f6ad8dea78f21385b8",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e3949a6d8154009a659945c790e12ef",
      "value": 1355256
     }
    },
    "2e62b29c76ed484baa01a84d51f7a8f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ae53b9c451c4e85a788263841a9673d",
      "placeholder": "​",
      "style": "IPY_MODEL_0035edbde4bd4c5f88204d663840d82b",
      "value": "vocab.json: 100%"
     }
    },
    "317647bc55b44fa7a37eb49a27034aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0481b1b1cd154fcc88aec905c51af76f",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5d0f4e93d13457a928f9a6fe0354d62",
      "value": 1042301
     }
    },
    "378a9ee69cf042979ecb8ca32e49839b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d229b4e30cd413b97cd73f868188fae",
      "placeholder": "​",
      "style": "IPY_MODEL_fb62786e1bc84ea3abee6a2e48ae1c73",
      "value": "merges.txt: 100%"
     }
    },
    "386d2fea56fa469aba4aaad455d84476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a811e921997e4b5ea50bb54f11c0e2d2",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_724a33f4afc5488ab7e967f87991d2e5",
      "value": 665
     }
    },
    "39808e3db3984ee2a0da0b7b89fcc886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe123833cff481cad9f6b0437193724": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_378a9ee69cf042979ecb8ca32e49839b",
       "IPY_MODEL_f95a2b58d6ca464db7a90dd4381c84ff",
       "IPY_MODEL_23d471228b4547edb3011815129cf0f4"
      ],
      "layout": "IPY_MODEL_687d1b24ef684204b43e56a0d8106376"
     }
    },
    "5a4e7b4c62ef4df79fefcbace8e9c26f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5de89c686c3c42d4b741790ff5b828e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6276a7d486aa41309f8e0e05948d1eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "687d1b24ef684204b43e56a0d8106376": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "724a33f4afc5488ab7e967f87991d2e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77a3a9ea86c24c3d840c8abfab3ec528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c59107dcb845431ab068406dcfb92391",
      "placeholder": "​",
      "style": "IPY_MODEL_f09319c0fe5c466c9663e591a3d7d650",
      "value": "tokenizer.json: 100%"
     }
    },
    "793c30e1bde44c13afe449303a34daac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84215a9176d143c09622554635a9d39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77a3a9ea86c24c3d840c8abfab3ec528",
       "IPY_MODEL_2ab8c56071a14a09b1e497c76c5e01e0",
       "IPY_MODEL_8a8472829d9c4a599365f08b658cb851"
      ],
      "layout": "IPY_MODEL_39808e3db3984ee2a0da0b7b89fcc886"
     }
    },
    "884e7212ec214bd8aa82939a280e22b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a8472829d9c4a599365f08b658cb851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de89c686c3c42d4b741790ff5b828e2",
      "placeholder": "​",
      "style": "IPY_MODEL_6276a7d486aa41309f8e0e05948d1eed",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 19.1MB/s]"
     }
    },
    "8b03415a476c48f6ad8dea78f21385b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98fd8faddb2842379c5f684262e4bdfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d229b4e30cd413b97cd73f868188fae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a54297f9f4f84544afa38a033c8c4025": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f07305b494ec4989afdff7e2a182d01e",
      "placeholder": "​",
      "style": "IPY_MODEL_98fd8faddb2842379c5f684262e4bdfc",
      "value": "config.json: 100%"
     }
    },
    "a811e921997e4b5ea50bb54f11c0e2d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac4d9ef301f5458388e7651a9fa97ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d411d16d4e4aefa1b0bb68c7ec92a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfd46bac58a44215bd33d57c8231d627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e62b29c76ed484baa01a84d51f7a8f5",
       "IPY_MODEL_317647bc55b44fa7a37eb49a27034aa0",
       "IPY_MODEL_24269a54be3e45f69a03a951b58c7ea9"
      ],
      "layout": "IPY_MODEL_00a9572004184110a072cd8efd0ed8b2"
     }
    },
    "c1ad28bc7d82404289f447648c9b4246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c59107dcb845431ab068406dcfb92391": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8ef0767e75546bb9c0d743fe319203e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5d0f4e93d13457a928f9a6fe0354d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f07305b494ec4989afdff7e2a182d01e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f09319c0fe5c466c9663e591a3d7d650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f73822f80c9c422b8ab94736e307f7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f95a2b58d6ca464db7a90dd4381c84ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_793c30e1bde44c13afe449303a34daac",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a4e7b4c62ef4df79fefcbace8e9c26f",
      "value": 456318
     }
    },
    "fb62786e1bc84ea3abee6a2e48ae1c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
